{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn =psycopg2.connect(host=\"35.200.234.61\",database=\"sales\", user=\"postgres\", password=\"cx6ac54nmgGtLD1y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"select * from snippet where snippet.task_id in ( select task.id from task where task.actor in ( \" \\\n",
    "      \"select org_user.userid from org_user where org_user.organizationid = {})) order by snippet.id asc limit \" \\\n",
    "      \"10000\".format(154)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_df = pd.read_sql_query(sql,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'from_time',\n",
       " 'to_time',\n",
       " 'confidence',\n",
       " 'text_',\n",
       " 'speaker',\n",
       " 'task_id',\n",
       " 'language_code',\n",
       " 'english_text',\n",
       " 'transliterated_text',\n",
       " 'is_final']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_df.drop(columns=[\"confidence\",\"language_code\",\"english_text\",\"transliterated_text\",\"is_final\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'from_time', 'to_time', 'text_', 'speaker', 'task_id'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine snippets based on speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_customer_sequence(input_df):\n",
    "    cached_snippets = []\n",
    "    df = input_df\n",
    "    if len(df) != 0:\n",
    "        for i in range(len(df)):\n",
    "            if len(cached_snippets) == 0:\n",
    "                cached_snippets.append({\"orignal_ids\": [df[\"id\"][i]], \"speaker\": df[\"speaker\"][i], \"text\": df[\"text_\"][i],\n",
    "                                        \"from_time\": df[\"from_time\"][i], \"to_time\": df[\"to_time\"][i],\n",
    "                                        \"task_id\": df[\"task_id\"][i]})\n",
    "            else:\n",
    "                if df[\"speaker\"][i] == cached_snippets[-1]['speaker'] and df[\"task_id\"][i] == cached_snippets[-1]['task_id']:\n",
    "                    cached_snippets[-1][\"orignal_ids\"].append(df[\"id\"][i])\n",
    "                    cached_snippets[-1][\"text\"] += \". \" + df[\"text_\"][i]\n",
    "                    cached_snippets[-1][\"to_time\"] = df[\"to_time\"][i]\n",
    "                    cached_snippets[-1][\"task_id\"] = df[\"task_id\"][i]\n",
    "                else:\n",
    "                    cached_snippets.append(\n",
    "                        {\"orignal_ids\": [df[\"id\"][i]], \"speaker\": df[\"speaker\"][i], \"text\": df[\"text_\"][i],\n",
    "                         \"from_time\": df[\"from_time\"][i], \"to_time\": df[\"to_time\"][i], \"task_id\": df[\"task_id\"][i]})\n",
    "        new_snippets_df = pd.DataFrame(cached_snippets)\n",
    "        return new_snippets_df\n",
    "    else:\n",
    "        return []    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = agent_customer_sequence(snippet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make the question extraction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER') #making a pattern matcher\n",
    "question_terms = [\"how\",\"can\",\"what\",\"where\",\"describe\",\"who\",\"when\",\"why\",\"?\"]\n",
    "patterns = [nlp(text) for text in question_terms]\n",
    "matcher.add(\"question\", None, *patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sentences(text):\n",
    "    if len(text.split()) > 0:\n",
    "        text_blob = TextBlob(text)\n",
    "        sentences=[]\n",
    "        for sen in text_blob.sentences:\n",
    "            sentences.append(str(sen))\n",
    "        return sentences\n",
    "    \n",
    "    \n",
    "def detect_questions(text):\n",
    "    sentences = detect_sentences(text)\n",
    "    question_parts=[]\n",
    "    for sen in sentences:\n",
    "        doc = nlp(sen)\n",
    "        if len(matcher(doc)) !=0:\n",
    "            matches = matcher(doc)\n",
    "            if str(doc[matches[0][1]:matches[0][2]]) != \"?\":\n",
    "                question_parts.append(str(doc[matches[0][1]:]))\n",
    "            else:\n",
    "                question_parts.append(str(sen))\n",
    "    return question_parts\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProcessPoolExecutor(max_workers=12) as exe:\n",
    "    future = list(exe.map(detect_questions,new_df.text.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"question\"]=future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pos(text):\n",
    "    doc = nlp(text)\n",
    "    nouns=[]\n",
    "    verbs=[]\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verbs.append(str(token.text))\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            nouns.append(str(token.text))\n",
    "    return nouns+verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporting(df):\n",
    "    report={\"snippet_ids\":[],\"speaker\":[],\"text\":[],\"type\":[],\"noun/verbs\":[],\"task_id\":[]}\n",
    "    old_taskid = df.task_id[0]\n",
    "    for i in range(len(df)):\n",
    "        if df.speaker[i] == \"Agent\" and len(df.question[i]) !=0:\n",
    "            try:\n",
    "                if df.task_id[i] == df.task_id[i+1]:\n",
    "                    report['snippet_ids'].append(df.orignal_ids[i])\n",
    "                    report['snippet_ids'].append(df.orignal_ids[i+1])\n",
    "                    report['speaker'].append(df.speaker[i])\n",
    "                    report['speaker'].append(df.speaker[i+1])\n",
    "                    report['text'].append(df.text[i])\n",
    "                    report['text'].append(df.text[i+1])\n",
    "                    report['type'].append(df.question[i])\n",
    "                    report['type'].append(\"response\")\n",
    "                    report['noun/verbs'].append([extract_pos(ques) for ques in df.question[i]])\n",
    "                    report['noun/verbs'].append(extract_pos(df.text[i+1]))\n",
    "                    report['task_id'].append(df.task_id[i])\n",
    "                    report['task_id'].append(df.task_id[i+1])\n",
    "                else:\n",
    "                    report['snippet_ids'].append(df.orignal_ids[i])\n",
    "                    report['snippet_ids'].append(\"\")\n",
    "                    report['speaker'].append(df.speaker[i])\n",
    "                    report['speaker'].append(\"\")\n",
    "                    report['text'].append(df.text[i])\n",
    "                    report['text'].append(\"\")\n",
    "                    report['type'].append(df.question[i])\n",
    "                    report['type'].append(\"\")\n",
    "                    report['noun/verbs'].append([extract_pos(ques) for ques in df.question[i]])\n",
    "                    report['noun/verbs'].append(\"\")\n",
    "                    report['task_id'].append(df.task_id[i])\n",
    "                    report['task_id'].append(\"\")\n",
    "            except IndexError:\n",
    "                pass \n",
    "    return report\n",
    "\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = reporting(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame.from_dict(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_excel(\"/home/andy/Desktop/noun_verb_list2.xlsx\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['orignal_ids',\n",
       " 'speaker',\n",
       " 'text',\n",
       " 'from_time',\n",
       " 'to_time',\n",
       " 'task_id',\n",
       " 'question']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker\n",
      "text\n",
      "from_time\n",
      "to_time\n",
      "task_id\n",
      "question\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5eabbd940972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(len(new_df.columns.to_list())):\n",
    "    print(new_df.columns.to_list()[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
