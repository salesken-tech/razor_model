{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      "goodness\n",
      "good\n",
      "goodness\n",
      "commodity\n",
      "trade_good\n",
      "good\n",
      "good\n",
      "full\n",
      "good\n",
      "good\n",
      "estimable\n",
      "good\n",
      "honorable\n",
      "respectable\n",
      "beneficial\n",
      "good\n",
      "good\n",
      "good\n",
      "just\n",
      "upright\n",
      "adept\n",
      "expert\n",
      "good\n",
      "practiced\n",
      "proficient\n",
      "skillful\n",
      "skilful\n",
      "good\n",
      "dear\n",
      "good\n",
      "near\n",
      "dependable\n",
      "good\n",
      "safe\n",
      "secure\n",
      "good\n",
      "right\n",
      "ripe\n",
      "good\n",
      "well\n",
      "effective\n",
      "good\n",
      "in_effect\n",
      "in_force\n",
      "good\n",
      "good\n",
      "serious\n",
      "good\n",
      "sound\n",
      "good\n",
      "salutary\n",
      "good\n",
      "honest\n",
      "good\n",
      "undecomposed\n",
      "unspoiled\n",
      "unspoilt\n",
      "good\n",
      "well\n",
      "good\n",
      "thoroughly\n",
      "soundly\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "for item in x:\n",
    "    for lemma in item.lemmas():\n",
    "        print(lemma.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_accepted_pos=[\"DT\",\"VBZ\",\"PRP\",\"VBP\",\"MD\",\"VB\",\"IN\"]\n",
    "def get_tokens(sentence):\n",
    "    return word_tokenize(sentence)\n",
    "\n",
    "def get_word_synonyms(word,max_synonims):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name())\n",
    "    return {word:list(set(synonyms))[:max_synonims] if len(list(set(synonyms))) > max_synonims else list(set(synonyms))}\n",
    "\n",
    "def get_synonyms(sentence):\n",
    "    s = time.time()\n",
    "    tokens = get_tokens(sentence)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    result=[]\n",
    "    for tag in pos_tags:\n",
    "        if tag[1] not in not_accepted_pos:\n",
    "            result.append(get_word_synonyms(tag[0],5))\n",
    "        else:\n",
    "            result.append({tag[0]:[]})\n",
    "    return result\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Is': []}, {'your': []}, {'child': ['tyke', 'kid', 'fry', 'nestling', 'tiddler']}, {'interested': ['matter_to', 'interested', 'interest', 'concerned', 'concern']}, {'in': []}, {'the': []}, {'course': ['flow', 'class', 'track', 'form', 'line']}]\n",
      "0.0042073726654052734\n"
     ]
    }
   ],
   "source": [
    "s=time.time()\n",
    "get_synonyms(\"Is your child interested in the course\")\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiktionaryparser import WiktionaryParser\n",
    "import json\n",
    "import re\n",
    "parser = WiktionaryParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(word):\n",
    "    \"\"\"This function is used to decode words coming from wordnet replacing hyphen or underscore with space\"\"\"\n",
    "    return re.sub('\\\\s+', \" \", word.replace('_', \" \").replace('-', \" \").strip())\n",
    "\n",
    "\n",
    "def encode(word):\n",
    "    \"\"\"This function is used to encode raw words by replacing spaces with underscore\"\"\"\n",
    "    return re.sub('\\\\s+', \"_\", word.strip())\n",
    "\n",
    "def get_synonyms_wiktionary(parser, word, language=None):\n",
    "    \"\"\"This function is used to find synonyms using wiktionary parser\"\"\"\n",
    "    output = parser.fetch(word, language)\n",
    "    x1 = json.dumps(output[0])\n",
    "    x2 = json.loads(x1)\n",
    "    synonyms = set()\n",
    "    for item in x2['definitions']:\n",
    "        for item2 in item['relatedWords']:\n",
    "            if item2[\"relationshipType\"] == \"synonyms\":\n",
    "                for item3 in item2['words']:\n",
    "                    synonyms.add(item3)\n",
    "    clear_synonyms = []\n",
    "    for item in synonyms:\n",
    "        clear_synonyms.append(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", item).replace(\":\", \"\").split(\",\"))\n",
    "    synonym_set = []\n",
    "    for x in clear_synonyms:\n",
    "        for y in x:\n",
    "            if (y not in synonym_set) and not (\"see thesaurus\" in y.lower()):\n",
    "                synonym_set.append(y)\n",
    "    synonym_set_d = set()\n",
    "    for syn in synonym_set:\n",
    "        synonym_set_d.add(decode(syn))\n",
    "    return set(synonym_set_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amelioration', 'improval'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_synonyms_wiktionary(parser,\"improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_synonyms_concept_net(word):\n",
    "    uri = \"http://api.conceptnet.io/c/en/\" + encode(str(word)) + \"?rel=/r/Synonym&limit=1000&format=json&language=en\"\n",
    "    response = requests.get(uri).json()\n",
    "    edges = response['edges']\n",
    "    synonyms = set()\n",
    "    for i, edge in enumerate(edges):\n",
    "        start = edge[\"start\"]\n",
    "        end = edge[\"end\"]\n",
    "        if \"language\" in start:\n",
    "            if start[\"language\"] == \"en\":\n",
    "                synonyms.add(start[\"label\"])\n",
    "        if \"language\" in end:\n",
    "            if end[\"language\"] == \"en\":\n",
    "                synonyms.add(end[\"label\"])\n",
    "    return list(set(synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"g'day\",\n",
       " 'greetings',\n",
       " 'farewell',\n",
       " 'minute',\n",
       " 'helloes',\n",
       " 'privet',\n",
       " 'cheerio',\n",
       " 'howdy',\n",
       " 'welcome',\n",
       " 'welcome home',\n",
       " 'wb',\n",
       " 'hello',\n",
       " 'ciao',\n",
       " 'helloji',\n",
       " 'single',\n",
       " 'yiff',\n",
       " 'hey',\n",
       " 'howzit',\n",
       " 'bye',\n",
       " 'magic word',\n",
       " 'hola',\n",
       " 'heaveno',\n",
       " 'heita',\n",
       " 'hale',\n",
       " '\"Hello\"',\n",
       " 'hello there',\n",
       " 'greeting',\n",
       " 'welcome back',\n",
       " 'art',\n",
       " 'aloha',\n",
       " 'trance music',\n",
       " 'rehi',\n",
       " 'Hello',\n",
       " 'uk',\n",
       " 'hygiene',\n",
       " 'earth',\n",
       " 'hardcore',\n",
       " 'lo',\n",
       " 'yello',\n",
       " 'alright',\n",
       " 'ey up',\n",
       " 'salute',\n",
       " \"what's new\",\n",
       " 'how',\n",
       " 'hellos',\n",
       " \"h'lo\",\n",
       " 'shaka',\n",
       " 'by',\n",
       " 'heylow',\n",
       " 'hail',\n",
       " 'branch',\n",
       " 'goodbye',\n",
       " 'yallo',\n",
       " 'hallo',\n",
       " 'greet',\n",
       " 'punishment',\n",
       " 'chimo',\n",
       " 'quantity',\n",
       " 'wave',\n",
       " 'airline',\n",
       " 'hello girl',\n",
       " 'helloed',\n",
       " 'hello yourself and see how you like it',\n",
       " 'nanu nanu',\n",
       " 'birthday',\n",
       " 'halloa',\n",
       " 'Another way to say \"Hi\"',\n",
       " 'hi',\n",
       " 'helloing',\n",
       " 'word up',\n",
       " 'a greeting people sometimes use',\n",
       " 'hullo',\n",
       " 'hollo',\n",
       " 'hiya',\n",
       " 'how-do-you-do',\n",
       " 'holla',\n",
       " 'opposite of goodbye',\n",
       " 'salutation']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_synonyms_concept_net(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(\"https://www.thesaurus.com/browse/improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=soup.find('section',{'class':'MainContentContainer'}).find_all(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in x:\n",
    "    for h in div.find_all(\"h2\"):\n",
    "        if \"Synonyms\" in h.text:\n",
    "            synonym_div=[div]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advance\n",
      "advancement\n",
      "change\n",
      "development\n",
      "enhancement\n",
      "gain\n",
      "growth\n",
      "increase\n",
      "progress\n",
      "recovery\n",
      "renovation\n",
      "revision\n",
      "rise\n",
      "upgrade\n",
      "amelioration\n",
      "amendment\n",
      "augmentation\n",
      "betterment\n",
      "civilization\n",
      "correction\n",
      "cultivation\n",
      "elevation\n",
      "enrichment\n",
      "furtherance\n",
      "meliorism\n",
      "preferment\n",
      "progression\n",
      "promotion\n",
      "rally\n",
      "reclamation\n",
      "rectification\n",
      "reformation\n",
      "regeneration\n",
      "upbeat\n",
      "upswing\n"
     ]
    }
   ],
   "source": [
    "for div in synonym_div:\n",
    "    for span in div.find_all(\"span\"):\n",
    "        for a in span.find_all(\"a\"):\n",
    "            print(a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
